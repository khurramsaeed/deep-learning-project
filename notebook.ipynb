{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-16d6dd43-0c3c-456a-89bc-538661ded0af",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# YOLO on Helmet dataset from Myanmar\n",
    "### Project 09 - Deep Learning (02456)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore state when working larger datasets (very handy if the session died out)\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-72fbc64b-b4d2-4084-a5c3-d75f6093cd53",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 146911,
    "execution_start": 1636386323623,
    "source_hash": "c0e5b7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure YOLO & OpenCV\n",
    "# !pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt\n",
    "# !apt install ffmpeg libsm6 libxext6 -y # Some machines require this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:\n",
      "/home/khurram/workspace/jupyter/deep-learning-project\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "print('Working directory:\\n' + os.getcwd())\n",
    "\n",
    "# Use this to unzip files (it seems if files already are unzipped nothing happens)\n",
    "def unzip(fileName, outputDir = ''):\n",
    "    with zipfile.ZipFile(os.getcwd() + '/' + fileName, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.getcwd() + '/' + outputDir)\n",
    "\n",
    "unzip_files = False\n",
    "\n",
    "if unzip_files:\n",
    "    unzip('part_1.zip', 'data')\n",
    "    unzip('part_2.zip', 'data')\n",
    "    unzip('part_3.zip', 'data')\n",
    "    unzip('part_4.zip', 'data')\n",
    "    unzip('part_5.zip', 'data')\n",
    "    unzip('part_6.zip', 'data')\n",
    "    unzip('part_7.zip', 'data')\n",
    "    # unzip('annotation.zip')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khurram/workspace/jupyter/deep-learning-project/data\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "directory = os.getcwd() + '/data'\n",
    "destination = os.getcwd() + '/data_yolo'\n",
    "print(directory) \n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for f in files:\n",
    "        shutil.move(root+\"/\"+f, destination+\"/\"+root.split(\"/\")[-1]+'-'+f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read classes and their respective indexes\n",
    "import pandas as pd\n",
    "classes = pd.read_csv('36_class.csv', sep=',', header=None, names=['class', 'index'])\n",
    "print(classes)\n",
    "\n",
    "# Helper functions\n",
    "def class_name_to_id(class_name):\n",
    "    return int(classes.loc[classes['class'] == class_name]['index'])\n",
    "\n",
    "def class_id_to_name(class_id):\n",
    "    return classes.loc[classes['index'] == class_id]['class'].str.cat(sep='\\n')\n",
    "\n",
    "print(\"\\nId of class DHelmet:\", class_name_to_id('DHelmet'))\n",
    "print(\"Class of id 2:\", class_id_to_name(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-2af60750-432a-48c2-9bf7-d277c9b0820c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10107,
    "execution_start": 1636386323660,
    "source_hash": "e040787c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_img(file_name, frame):\n",
    "    path = file_name + \"-\" \n",
    "    if(frame < 10):\n",
    "        path += \"0\"\n",
    "    path += str(frame) + \".jpg\"\n",
    "\n",
    "    img = plt.imread(path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "def draw_annotation(fileName, frame):\n",
    "    with open('annotation/' + fileName + '.csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "\n",
    "        rectangleList = []\n",
    "\n",
    "        for row in reader:\n",
    "            if (row['frame_id'] == str(frame)):\n",
    "                rectangleList.append(plt.Rectangle((int(row['x']), int(row['y'])), int(row['w']), int(row['h']), fill=None, color=(0,0,1)))\n",
    "        \n",
    "        for rectangle in rectangleList:\n",
    "            plt.gca().add_patch(rectangle)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# for i in range(1, 10):\n",
    "#     draw_annotation('Bago_highway_1', i)\n",
    "draw_img('data/part_1/Bago_highway_1', 1)\n",
    "draw_annotation('Bago_highway_1', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotation data and convert it to YOLOv5\n",
    "\n",
    "## Read and prepare\n",
    "def annotate_prepare(file_name):\n",
    "    groups = pd.read_csv(file_name, sep=',', header=0).groupby('frame_id')\n",
    "    # Print one group\n",
    "    # print(groups.get_group(1))\n",
    "    data = []\n",
    "    # Create datastructure and format\n",
    "    for frame, group in groups:\n",
    "        annotation = {}\n",
    "        annotation['filename'] = str(frame)\n",
    "        annotation['image_size'] = tuple(['1920', '1080'])\n",
    "        annotation['bboxes'] = []\n",
    "        #print(formatted)\n",
    "        #print(frame, group)\n",
    "        for _, row in group.iterrows():\n",
    "            bbox = {}\n",
    "            bbox['id'] = row['track_id']\n",
    "            bbox['class'] = row['label']\n",
    "            bbox['x'] = row['x']\n",
    "            bbox['y'] = row['y']\n",
    "            bbox['w'] = row['w']\n",
    "            bbox['h'] = row['h']\n",
    "            annotation['bboxes'].append(bbox)\n",
    "        # print(annotation)\n",
    "        data.append(annotation)\n",
    "    return data\n",
    "\n",
    "# TEST CODE\n",
    "# bago_highway_1 = annotate_prepare('Bago_highway_1.csv')\n",
    "# print(bago_highway_1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to YOLO5\n",
    "def annotate_yolo5(frame_annotation, output_path):\n",
    "    print_buffer = []\n",
    "    \n",
    "    for box in frame_annotation['bboxes']:\n",
    "        try:\n",
    "            class_id = class_name_to_id(box['class'])\n",
    "        except KeyError:\n",
    "            print(\"Invalid class\")\n",
    "        \n",
    "        # Transform the bounding box as per the format required by YOLO5\n",
    "        box_center_x = box['x'] + (box['w'] / 2)\n",
    "        box_center_y = box['y'] + (box['h'] / 2)\n",
    "        box_width    = box['w']\n",
    "        box_height   = box['h']\n",
    "        \n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h = frame_annotation[\"image_size\"]\n",
    "        box_center_x /= float(image_w) \n",
    "        box_center_y /= float(image_h) \n",
    "        box_width    /= float(image_w) \n",
    "        box_height   /= float(image_h)\n",
    "        #Write the bbox details to the file \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, box_center_x, box_center_y, box_width, box_height))\n",
    "\n",
    "    # Name of the file which we have to save \n",
    "    save_file_name = os.path.join(output_path, frame_annotation['filename'] + '.txt')\n",
    "    save_file_data = \"\\n\".join(print_buffer)\n",
    "\n",
    "    # Save the annotation to disk\n",
    "    print(save_file_data, file = open(save_file_name, \"w\"))\n",
    "\n",
    "# TEST CODE\n",
    "# annotate_yolo5(bago_highway_1[2], 'part_1/Bago_highway_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all annotations and save them as .txt files\n",
    "from pathlib import Path\n",
    "\n",
    "# Flag to convert annotations to YOLOv5 format default `False`\n",
    "run_yolo5_annotation_conversion = True\n",
    "\n",
    "if run_yolo5_annotation_conversion:    \n",
    "    # Get the annotations\n",
    "    annotations = [os.path.join('annotation', x) for x in os.listdir('annotation') if x[-3:] == \"csv\"]\n",
    "    annotations.sort()\n",
    "\n",
    "    print(\"Annotation count:\", len(annotations))\n",
    "\n",
    "    for annotation in tqdm(annotations):\n",
    "        prepared_output = annotate_prepare(annotation)\n",
    "\n",
    "        output_dir = annotation.split('/')[1].split('.')[0]\n",
    "        output_path = os.path.join('annotation', output_dir)\n",
    "\n",
    "        # Create output directory if does not exists\n",
    "        Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for prepared_frame in prepared_output:\n",
    "            annotate_yolo5(prepared_frame, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the annotations to be correctly calculated\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "def plot_bounding_box(frame, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(frame)\n",
    "    \n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    " \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "\n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name(int(obj_cls)), fill=(255,0,0,255))\n",
    "    \n",
    "        plt.imshow(np.array(image))\n",
    "        plt.show()\n",
    "\n",
    "# Get any random annotation file \n",
    "annotation_file = 'annotation/Bago_highway_1/3.txt'\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "\n",
    "#Get the corresponding image file\n",
    "image_file = 'part_1/Bago_highway_1/03.jpg'\n",
    "assert os.path.exists(image_file)\n",
    "\n",
    "#Load the image\n",
    "image = Image.open(image_file)\n",
    "\n",
    "#Plot the Bounding Box\n",
    "plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare directories for YOLO5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-1bbe4ccb-c731-4ad5-a789-d79c8c8e648a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1438,
    "execution_start": 1636386749001,
    "source_hash": "b6446922",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# !pip install opencv-python\n",
    "import cv2\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3432fd26-5b91-468a-a89c-15a295636b95' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "77194cdf-b007-4f0f-9d97-6c8bd25caff6",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
