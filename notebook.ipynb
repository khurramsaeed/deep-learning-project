{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-16d6dd43-0c3c-456a-89bc-538661ded0af",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# YOLO on Helmet dataset from Myanmar\n",
    "### Project 09 - Deep Learning (02456)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore state when working larger datasets (very handy if the session died out)\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-72fbc64b-b4d2-4084-a5c3-d75f6093cd53",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 146911,
    "execution_start": 1636386323623,
    "source_hash": "c0e5b7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure YOLO & OpenCV\n",
    "# !pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt\n",
    "# !apt install ffmpeg libsm6 libxext6 -y # Some machines require this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:\n",
      "/home/khurram/workspace/jupyter/deep-learning-project\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "print('Working directory:\\n' + os.getcwd())\n",
    "\n",
    "# Use this to unzip files (it seems if files already are unzipped nothing happens)\n",
    "def unzip(fileName, outputDir = ''):\n",
    "    with zipfile.ZipFile(os.getcwd() + '/' + fileName, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.getcwd() + '/' + outputDir)\n",
    "\n",
    "unzip_files = True\n",
    "\n",
    "if unzip_files:\n",
    "    #unzip('part_1.zip', 'data')\n",
    "    #unzip('part_2.zip', 'data')\n",
    "    #unzip('part_3.zip', 'data')\n",
    "    #unzip('part_4.zip', 'data')\n",
    "    #unzip('part_5.zip', 'data')\n",
    "    #unzip('part_6.zip', 'data')\n",
    "    unzip('part_7.zip', 'data')\n",
    "    # unzip('annotation.zip')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                class  index\n",
      "0                                 DNoHelmetP1NoHelmet      0\n",
      "1                                     DHelmetP1Helmet      1\n",
      "2                                             DHelmet      2\n",
      "3                                           DNoHelmet      3\n",
      "4                                   DHelmetP1NoHelmet      4\n",
      "5                         DHelmetP0NoHelmetP1NoHelmet      5\n",
      "6                         DHelmetP1NoHelmetP2NoHelmet      6\n",
      "7                       DNoHelmetP1NoHelmetP2NoHelmet      7\n",
      "8                           DHelmetP1NoHelmetP2Helmet      8\n",
      "9                                   DNoHelmetP1Helmet      9\n",
      "10                DHelmetP0NoHelmetP1NoHelmetP2Helmet     10\n",
      "11                      DNoHelmetP0NoHelmetP1NoHelmet     11\n",
      "12                                DNoHelmetP0NoHelmet     12\n",
      "13                                  DHelmetP0NoHelmet     13\n",
      "14                          DNoHelmetP1HelmetP2Helmet     14\n",
      "15                            DHelmetP1HelmetP2Helmet     15\n",
      "16            DNoHelmetP0NoHelmetP1NoHelmetP2NoHelmet     16\n",
      "17              DHelmetP0NoHelmetP1NoHelmetP2NoHelmet     17\n",
      "18                          DHelmetP0NoHelmetP1Helmet     18\n",
      "19                          DHelmetP1HelmetP2NoHelmet     19\n",
      "20            DNoHelmetP1NoHelmetP2NoHelmetP3NoHelmet     20\n",
      "21                                    DHelmetP0Helmet     21\n",
      "22                        DNoHelmetP1NoHelmetP2Helmet     22\n",
      "23                  DHelmetP0NoHelmetP1HelmetP2Helmet     23\n",
      "24                DHelmetP1NoHelmetP2NoHelmetP3Helmet     24\n",
      "25                            DHelmetP0HelmetP1Helmet     25\n",
      "26                        DNoHelmetP0NoHelmetP1Helmet     26\n",
      "27              DHelmetP1NoHelmetP2NoHelmetP3NoHelmet     27\n",
      "28  DNoHelmetP0NoHelmetP1NoHelmetP2NoHelmetP3NoHelmet     28\n",
      "29                  DHelmetP0HelmetP1NoHelmetP2Helmet     29\n",
      "30                DHelmetP0HelmetP1NoHelmetP2NoHelmet     30\n",
      "31                        DNoHelmetP0HelmetP1NoHelmet     31\n",
      "32                    DHelmetP0HelmetP1HelmetP2Helmet     32\n",
      "33      DHelmetP0NoHelmetP1NoHelmetP2NoHelmetP3Helmet     33\n",
      "34              DNoHelmetP0NoHelmetP1NoHelmetP2Helmet     34\n",
      "35    DHelmetP0NoHelmetP1NoHelmetP2NoHelmetP3NoHelmet     35\n",
      "\n",
      "Id of class DHelmet: 2\n",
      "Class of id 2: DHelmet\n"
     ]
    }
   ],
   "source": [
    "# Read classes and their respective indexes\n",
    "import pandas as pd\n",
    "classes = pd.read_csv('36_class.csv', sep=',', header=None, names=['class', 'index'])\n",
    "print(classes)\n",
    "\n",
    "# Helper functions\n",
    "def class_name_to_id(class_name):\n",
    "    return int(classes.loc[classes['class'] == class_name]['index'])\n",
    "\n",
    "def class_id_to_name(class_id):\n",
    "    return classes.loc[classes['index'] == class_id]['class'].str.cat(sep='\\n')\n",
    "\n",
    "print(\"\\nId of class DHelmet:\", class_name_to_id('DHelmet'))\n",
    "print(\"Class of id 2:\", class_id_to_name(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            video_id         Set\n",
      "0     Bago_highway_1  validation\n",
      "1    Bago_highway_10        test\n",
      "2    Bago_highway_11    training\n",
      "3    Bago_highway_12    training\n",
      "4    Bago_highway_13    training\n",
      "..               ...         ...\n",
      "905      Yangon_II_5    training\n",
      "906      Yangon_II_6        test\n",
      "907      Yangon_II_7    training\n",
      "908      Yangon_II_8    training\n",
      "909      Yangon_II_9  validation\n",
      "\n",
      "[910 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split = pd.read_csv('data_split.csv', sep=',', header=0, names=['video_id', 'Set'])\n",
    "print(data_split)\n",
    "\n",
    "# Helper functions\n",
    "def get_video_set(video_id):\n",
    "    return data_split.loc[data_split['video_id'] == video_id]['Set'].str.cat(sep='\\n')\n",
    "\n",
    "get_video_set('Bago_highway_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 37.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khurram/workspace/jupyter/deep-learning-project/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [00:07, 19.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "directory = os.getcwd() + '/data'\n",
    "destination = os.getcwd() + '/data_yolo'\n",
    "# Create output directory if does not exists\n",
    "Path(destination).mkdir(parents=True, exist_ok=True)\n",
    "print(directory) \n",
    "for root, dirs, files in tqdm(os.walk(directory)):\n",
    "    for f in files:\n",
    "        try:\n",
    "            output_by_set = destination + '/' + get_video_set(root.split(\"/\")[-1])\n",
    "            # Create output directory if does not exists\n",
    "            Path(output_by_set).mkdir(parents=True, exist_ok=True)\n",
    "            shutil.move(root+\"/\"+f, output_by_set+\"/\"+root.split(\"/\")[-1]+'-'+f)\n",
    "        except:\n",
    "            print('')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-2af60750-432a-48c2-9bf7-d277c9b0820c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10107,
    "execution_start": 1636386323660,
    "source_hash": "e040787c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_img(file_name, frame):\n",
    "    path = file_name + \"-\" \n",
    "    if(frame < 10):\n",
    "        path += \"0\"\n",
    "    path += str(frame) + \".jpg\"\n",
    "\n",
    "    img = plt.imread(path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "def draw_annotation(fileName, frame):\n",
    "    with open('annotation/' + fileName + '.csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "\n",
    "        rectangleList = []\n",
    "\n",
    "        for row in reader:\n",
    "            if (row['frame_id'] == str(frame)):\n",
    "                rectangleList.append(plt.Rectangle((int(row['x']), int(row['y'])), int(row['w']), int(row['h']), fill=None, color=(0,0,1)))\n",
    "        \n",
    "        for rectangle in rectangleList:\n",
    "            plt.gca().add_patch(rectangle)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# for i in range(1, 10):\n",
    "#     draw_annotation('Bago_highway_1', i)\n",
    "draw_img('data_yolo/Bago_highway_1', 1)\n",
    "draw_annotation('Bago_highway_1', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotation data and convert it to YOLOv5\n",
    "\n",
    "## Read and prepare\n",
    "def annotate_prepare(file_name):\n",
    "    groups = pd.read_csv(file_name, sep=',', header=0).groupby('frame_id')\n",
    "    # Print one group\n",
    "    # print(groups.get_group(1))\n",
    "    data = []\n",
    "    # Create datastructure and format\n",
    "    for frame, group in groups:\n",
    "        annotation = {}\n",
    "        annotation['filename'] = str(frame)\n",
    "        annotation['image_size'] = tuple(['1920', '1080'])\n",
    "        annotation['bboxes'] = []\n",
    "        #print(formatted)\n",
    "        #print(frame, group)\n",
    "        for _, row in group.iterrows():\n",
    "            bbox = {}\n",
    "            bbox['id'] = row['track_id']\n",
    "            bbox['class'] = row['label']\n",
    "            bbox['x'] = row['x']\n",
    "            bbox['y'] = row['y']\n",
    "            bbox['w'] = row['w']\n",
    "            bbox['h'] = row['h']\n",
    "            annotation['bboxes'].append(bbox)\n",
    "        # print(annotation)\n",
    "        data.append(annotation)\n",
    "    return data\n",
    "\n",
    "# TEST CODE\n",
    "# bago_highway_1 = annotate_prepare('Bago_highway_1.csv')\n",
    "# print(bago_highway_1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to YOLO5\n",
    "def annotate_yolo5(frame_annotation, output_path, directory_prefix):\n",
    "    print_buffer = []\n",
    "    \n",
    "    for box in frame_annotation['bboxes']:\n",
    "        try:\n",
    "            class_id = class_name_to_id(box['class'])\n",
    "        except KeyError:\n",
    "            print(\"Invalid class\")\n",
    "        \n",
    "        # Transform the bounding box as per the format required by YOLO5\n",
    "        box_center_x = box['x'] + (box['w'] / 2)\n",
    "        box_center_y = box['y'] + (box['h'] / 2)\n",
    "        box_width    = box['w']\n",
    "        box_height   = box['h']\n",
    "        \n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h = frame_annotation[\"image_size\"]\n",
    "        box_center_x /= float(image_w) \n",
    "        box_center_y /= float(image_h) \n",
    "        box_width    /= float(image_w) \n",
    "        box_height   /= float(image_h)\n",
    "        #Write the bbox details to the file \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, box_center_x, box_center_y, box_width, box_height))\n",
    "\n",
    "    # Name of the file which we have to save\n",
    "    #output_path.split('/')[1]\n",
    "    annotation_name = '0' + frame_annotation['filename'] if int(frame_annotation['filename']) < 10 else frame_annotation['filename']\n",
    "    save_file_name = os.path.join(output_path, directory_prefix +'-' + annotation_name + '.txt')\n",
    "    save_file_data = \"\\n\".join(print_buffer)\n",
    "\n",
    "    # Save the annotation to disk\n",
    "    print(save_file_data, file = open(save_file_name, \"w\"))\n",
    "\n",
    "# TEST CODE\n",
    "# annotate_yolo5(bago_highway_1[2], 'part_1/Bago_highway_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation count: 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 910/910 [02:24<00:00,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert all annotations and save them as .txt files\n",
    "from pathlib import Path\n",
    "\n",
    "# Flag to convert annotations to YOLOv5 format default `False`\n",
    "run_yolo5_annotation_conversion = True\n",
    "\n",
    "output_path = os.getcwd() + '/data_yolo'\n",
    "\n",
    "if run_yolo5_annotation_conversion:\n",
    "    # Get the annotations\n",
    "    annotations = [os.path.join('annotation', x) for x in os.listdir('annotation') if x[-3:] == \"csv\"]\n",
    "    annotations.sort()\n",
    "    print(\"Annotation count:\", len(annotations))\n",
    "\n",
    "    # Create output directory if does not exists\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for annotation in tqdm(annotations):\n",
    "        prepared_output = annotate_prepare(annotation)\n",
    "        directory_prefix = annotation.split('/')[1].split('.')[0]\n",
    "        \n",
    "        # Get the video set id\n",
    "        output_by_set = output_path + '/' + get_video_set(directory_prefix)\n",
    "        # Create output directory if does not exists\n",
    "        Path(output_by_set).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        for prepared_frame in prepared_output:\n",
    "            annotate_yolo5(prepared_frame, output_by_set, directory_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the annotations to be correctly calculated\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "def plot_bounding_box(frame, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(frame)\n",
    "    \n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    " \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "\n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name(int(obj_cls)), fill=(255,0,0,255))\n",
    "    \n",
    "        plt.imshow(np.array(image))\n",
    "        plt.show()\n",
    "\n",
    "# Get any random annotation file \n",
    "annotation_file = 'annotation/Bago_highway_1/3.txt'\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "\n",
    "#Get the corresponding image file\n",
    "image_file = 'data_yolo/Bago_highway_1-03.jpg'\n",
    "assert os.path.exists(image_file)\n",
    "\n",
    "#Load the image\n",
    "image = Image.open(image_file)\n",
    "\n",
    "#Plot the Bounding Box\n",
    "plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare directories for YOLO5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-1bbe4ccb-c731-4ad5-a789-d79c8c8e648a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1438,
    "execution_start": 1636386749001,
    "source_hash": "b6446922",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# !pip install opencv-python\n",
    "import cv2\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3432fd26-5b91-468a-a89c-15a295636b95' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "77194cdf-b007-4f0f-9d97-6c8bd25caff6",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
